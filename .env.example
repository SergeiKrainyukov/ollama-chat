# Конфигурация Ollama Chat API

# Модель Ollama по умолчанию
# Легкая модель для экономии ресурсов (требует ~4 GB RAM)
OLLAMA_MODEL=qwen2.5:1.5b

# Другие варианты моделей:
# OLLAMA_MODEL=qwen2.5:3b      # Лучший баланс качества/ресурсов (требует ~6 GB RAM)
# OLLAMA_MODEL=qwen3:4b        # Более качественная модель (требует ~8 GB RAM)
# OLLAMA_MODEL=phi3:3.8b       # Хорошо работает на английском (требует ~6 GB RAM)
# OLLAMA_MODEL=gemma:2b        # Очень легкая модель от Google (требует ~4 GB RAM)

# URL Ollama сервера (внутри Docker используйте http://ollama:11434)
OLLAMA_URL=http://ollama:11434

# Порт API сервера
PORT=8080

# Хост API сервера
HOST=0.0.0.0